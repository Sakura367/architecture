## 大key
BigKey指的是redis中一些key value值很大,这些key在序列化与反序列化过程中花费的时间很大。操作bigkey的通常比较耗时，也就意味着阻塞Redis可能性越大，占用的流量同时也会变得很大。

生产环境中，综合衡量运维和环境的情况，给大key定义参考值如下：
- string类型的key超过10KB
- hash/set/zset/list等数据结构中元素个数大于5k/整体占用内存大于10MB
```
查看bigkey：redis-cli -h ip地址 -p 端口号 --bigkeys
```

### 场景
1. 热门话题下评论、答案排序场景。
2. 大V的粉丝列表。
3. 使用不恰当，或者对业务预估不准确、不及时进行处理垃圾数据等。

### 问题
1. 内存不均：集群模式在slot分片均匀情况下，会出现数据和查询倾斜情况，部分有大key的Redis节点占用内存多，QPS高。
2. 阻塞请求：redis为单线程，单value较大读写需要较长的处理时间，会阻塞后续的请求处理；大key相关的删除或者自动过期时，会出现qps突降或者突升的情况，极端情况下，会造成主从复制异常，Redis服务阻塞无法响应请求。
- 大key的体积与删除耗时可参考下表：
    | key | field | 数量耗时 |
    |  :---:  | :---:  | :---: |
    | Hash | 100万 | 1000ms |
    | List | 100万 | 1000ms |
    | Set | 100万 | 1000ms |
    | Sorted Set | 100万 | 1000ms |
3. 阻塞网络：单value较大时会占用服务器网卡较多带宽，可能会影响该服务器上的其他Redis实例或者应用。

### 大key与大value
Dict字典结构中，存储数据的主题为DictHt，即哈希表。而哈希表本质上是一个DictEntry（哈希表节点）的数组，并且使用链表法解决哈希冲突问题

所以在这里实际存储时，key和value都是存储在DictEntry中的。所以基本上来说，大key和大value带来的内存不均和网络IO压力都是一致的，只是key相较于value还多一个做hashcode和比较的过程（链表中进行遍历比较key），会有更多的内存相关开销。

总结：
1. 大key和大value的危害是一致的：内存不均、阻塞请求、阻塞网络。
2. key由于比value需要做更多的操作如hashcode、链表中比较等操作，所以会比value更多一些内存相关开销。

### 优化
1. 业务拆分，将key的含义更细粒度化，避免大key出现。
2. 数据结构上拆分。如果大key是个大json，可以通过mset的方式，将这个key的内容打散到各个实例中，减小大key对数据量倾斜的影响；如果是大list，可以拆成list_1,list_2,list_N；其他数据结构同理。（可以考虑增加单独key存储大key被拆分的个数或元数据信息）
3. 对于长文本，更建议使用文档型数据库例如MongoDB等。
4. 对一致性要求不高的场景，尝试使用客户端缓存。（只解决了redis的阻塞问题，但机器或局域网的带宽问题没有改善）
5. 对大key的压缩。相当于用cpu资源来降低网络io，其中google提出的snappy算法较常用。
6. 对于hash等数据结构，需要注意业务是否可以引入定期清理无效field的机制。

## 热key
热key问题就是，突然有几十万的请求去访问redis上的某个特定key。那么，这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机。
```
查看hotkey：redis-cli -h ip地址 -p 端口号 --hotkeys
```

### 场景
1. 用户消费的数据远大于生产的数据（热卖商品、热点新闻、热点评论、明星直播）。
在日常工作生活中一些突发的的事件，例如：双十一期间某些热门商品的降价促销，当这其中的某一件商品被数万次点击浏览或者购买时，会形成一个较大的需求量，这种情况下就会造成热点问题。
同理，被大量刊发、浏览的热点新闻、热点评论、明星直播等，这些典型的读多写少的场景也会产生热点问题。

2. 请求分片集中，超过单 Server 的性能极限。
在服务端读数据进行访问时，往往会对数据进行分片切分，此过程中会在某一主机 Server 上对相应的 Key 进行访问，当访问超过 Server 极限时，就会导致热点 Key 问题的产生。

### 问题
1. 流量集中，达到物理网卡上限。
2. 请求过多，缓存分片服务被打垮。
3. DB 击穿，引起业务雪崩。

当某一热点 Key 的请求在某一主机上超过该主机网卡上限时，由于流量的过度集中，会导致服务器中其它服务无法进行。

如果热点过于集中，热点 Key 的缓存过多，超过目前的缓存容量时，就会导致缓存分片服务被打垮现象的产生。

当缓存服务崩溃后，此时再有请求产生，会缓存到后台 DB 上，由于DB 本身性能较弱，在面临大请求时很容易发生请求穿透现象，会进一步导致雪崩现象，严重影响设备的性能。 

### 解决方案
1. 热key统计可以使用LFU数据结构，将最热topN的key进行统计，然后在client端使用本地缓存，从而降低redis集群对热key的访问量，但这种方法带来两个问题：
- 如果对所有热key进行本地缓存，那么本地缓存是否会过大，从而影响应用程序本身的性能开销。
- 可能需要保证本地缓存和redis数据的一致性。
2. 将热key加上前缀或者后缀，把热key的数量从1个变成实例个数，利用分片特性将这n个key分散在不同节点上，这样就可以在访问的时候，采用客户端负载均衡的方式，随机选择一个key进行访问，将访问压力分散到不同的实例中。
- 缺点：就是缓存的维护成本大。假如有n为100，则更新或者删除key的时候需要操作100个key。
3. 利用读写分离，通过主从复制的方式，增加slave节点来实现读请求的负载均衡。这个方案明显的缺点就是使用机器硬抗热key的数据，资源耗费严重；而且引入读写分离架构，增加节点数量，都会增加系统的复杂度降低稳定性。